---
title: "extract and refine sequences of interest from metagenomic assemblies"
output: html_notebook
editor_options: 
chunk_output_type: inline
---

Dependencies
```{r setup, include=FALSE}
#rm(list=ls());if(is.null(dev.list()["RStudioGD"])){} else {dev.off(dev.list()["RStudioGD"])};cat("\014")
library(tidyverse)
library(furrr)
library(Rsamtools)
library(vroom)
library(Biostrings)
library(seqinr)
library(dplyr)
library (here)

#Load postgres server running on Alpena
pg <- DBI::dbConnect(RPostgres::Postgres(),dbname = "glamr_data", host = "cayman.earth.lsa.umich.edu", port = "5432", user = "glamr_admin", password = "glamr2023")

#Load GLAMR GTDBTK data
gtdb <- tbl(pg, "GTDB") %>% 
  collect() %>% 
  mutate(sample = str_extract(bin, "samp_\\d+")) 

#Load GLAMR CheckM data
checkM <- tbl(pg, "checkm") %>% 
  collect() %>% 
  mutate(sample = str_extract(bin, "samp_\\d+")) 

#Load GLAMR sample data
glamr_samples_pg <- tbl(pg, "glamr_samples") %>% 
  collect() 

#set working directory
here("/geomicro/data2/pdenuyl2/metagenomics_wg24/2024-25-working-group")

 
``` 

---Outline---
PART A: Identify contigs
1.) Setup of general GLAMR data and assemblies of interest for BLASTN, filter data set, symlink processed contigs
2.) BLAST assemblies to identify contigs that possess gvpA or gvpC (source - doi: https://doi.org/10.1038/nrmicro2834) 
3.) Keep only contigs that contain gvpA or gvpC genes

PART B: Classify/visualize contigs of interest
4.) Run Kraken to annotate contigs with taxonomic classification
5.) Analyze Kraken output to determine Microcystis contigs
6.) Run Bakta to create .gbf (newer version of .gbk) files for clinker visulaization
7.) Run Clinker to visualize Microcystis contigs with both gvpA and gvpC genes

PART C: Extract all genes from contig
8.) Extract genes from single contig using bedtools
9.) BLAST assemblies using genes as database 
10.) Organize into fasta files for each target (tree building, etc.)

1.) Assembly path setup
```{r}

#Identify samples by set (i.e. project) of interest in GLAMR - western Lake Erie & Saginaw Bay, Lake Huron from set_41 ONLY
GLAMR_sample_table_set41 <- glamr_samples_pg %>% 
                              filter(StudyID %in% "set_41")           #include only StudyID of interest (NOAA-GLERL metagenomes)

#Save data table used (Last used/saved: April 23, 2025)
##write_csv(GLAMR_sample_table_set41, file = "../data/extract_refine_seqs_gvp/GLAMR_sample_table_pg_SB_23Apr25.csv")
GLAMR_sample_table_set41_read <- read_csv(file = "../data/extract_refine_seqs_gvp/GLAMR_sample_table_pg_SB_23Jan25.csv", show_col_types = FALSE)
                               
GLAMR_sample_table_set41 %>% distinct(SampleID) %>% dplyr::count() #218 metagenome samples in GLAMR - April 23, 2025

#Randomly sample 5 rows for a smaller dataset (just for April 2025 group walkthrough)
set.seed(5) #set seed for random selection of dataset - makes for easier testing/walkthrough
set41_subset_i <- sample_n(GLAMR_sample_table_set41, 5) 

#For example, include additional sample:
set_41_samp_4400 <- GLAMR_sample_table_set41_read %>%
                          filter(SampleID == "samp_4400")

set41_subset <- rbind(set41_subset_i, set_41_samp_4400)

#Gather all read paths to megahit assemblies to process through BLASTN, sym link to new path
assembly_paths <- tibble(sample = set41_subset$SampleID) %>%
                mutate(read_path = str_glue("/geomicro/data2/kiledal/GLAMR/data/omics/metagenomes/{sample}/assembly/megahit_noNORM/final.contigs.renamed.fa"),
                       new_path = str_glue("../data/extract_refine_seqs_gvp/assembly/megahit_noNORM/{sample}_final.contigs.renamed.fa"))
                                  
#symbolic link read_paths
file.symlink(assembly_paths$read_path, assembly_paths$new_path) 

```

2.) BLASTN assemblies using snakemake
```{bash}

snakemake run_blastn_assemblies_gvpAC --profile config/profiles/vondamm/

```

3a.) Process BLASTN output to get list of contigs that contain gvpA and gvpC - keep only these contigs
```{r}

#Make list of blastn result outputs
blastn_assemblies_list <-  system("ls ../data/extract_refine_seqs_gvp/output/blastn/*blastdbbuoyancygvpAC_contigs_blastn.tsv", intern=TRUE) 

#Include only files with results in list
blastn_assemblies_list_results <- blastn_assemblies_list[file.size(blastn_assemblies_list) > 0]

#Bind rows of all contig blastn results
blastn_assemblies_results_vroom <- vroom(blastn_assemblies_list_results, col_names = FALSE, show_col_types = FALSE, delim = "\t")

#Add column names - corresponding to blast output flag -outfmt '6 std qcovs stitle'
colnames(blastn_assemblies_results_vroom) <- c("qseqid", "sseqid", "pident", "length", "mismatch", "gapopen", "qstart", "qend", "sstart", "send", "evalue", "bitscore", "qcovs", "stitle", "qlen") #added qlen Sept 26, 2024 for Buoyancy analysis

#Column name reference: https://www.metagenomics.wiki/tools/blast/blastn-output-format-6
#1.  qseqid      query or source (e.g., gene) sequence id
#2.  sseqid      subject  or target (e.g., reference genome) sequence id
#3.  pident      percentage of identical matches
#4.  length      alignment length (sequence overlap)
#5.  mismatch    number of mismatches
#6.  gapopen     number of gap openings
#7.  qstart      start of alignment in query
#8.  qend        end of alignment in query
#9.  sstart      start of alignment in subject
#10. send        end of alignment in subject
#11. evalue      expect value
#12. bitscore    bit score
#13. qcovs       query coverage per subject
#14. stitle      subject title
#15. qlen        query length

#Make column for target and sample ids
blastn_assemblies_results_vroom_add <- blastn_assemblies_results_vroom %>% mutate(target = substr(sseqid, 1, 3),
                                                                                  gene_target = substr(sseqid, 1,4),
                                                                                  SampleID = qseqid %>% str_extract("samp_.*_") %>% str_sub(end = -2))

#Keep contigs with both gvpA and gvpC genes (no length limitation)
blastn_buoyancy_assemblies_gvpAC <- blastn_assemblies_results_vroom_add %>% 
                                                    # Group by qseqid
                                                    group_by(qseqid) %>%
                                                    # Keep only qseqid groups where both gvpA and gvpC are present
                                                    filter(all(c("gvpa", "gvpc") %in% gene_target)) %>%
                                                    # Ungroup to finalize
                                                    ungroup() %>%
                                                    #group_by(gene_target) %>%
                                                  distinct(qseqid, .keep_all = TRUE) %>% 
                                                  select(qseqid, evalue, qlen, SampleID, qstart, qend) #gene_target) 

#Merge metadata, so there's a geo_loc_name for each sample
GLAMR_sample_table_set41_read_select <- GLAMR_sample_table_set41_read %>%
                                                                  select("SampleID", "geo_loc_name")

blastn_buoyancy_assemblies_gvpAC_geo_loc_name <- left_join(blastn_buoyancy_assemblies_gvpAC, GLAMR_sample_table_set41_read_select, by = "SampleID") %>%
                                                                  mutate(query_name = paste0(qseqid, "_", geo_loc_name) %>%
                                                                           gsub(" ", "_", .))

#Create list of gvp hits
gvp_contigs <- blastn_buoyancy_assemblies_gvpAC_geo_loc_name %>%
                          filter(qlen >= 3500) %>%                  #keep only hits longer than 3500 bases
                          select(qseqid, SampleID, query_name)

```

3b.) Extract contigs for kraken and clinker figure building
```{r}

####################################
#Extract contigs with gvpA and gvpC + longer than 3,500bp#
####################################

for (seq in gvp_contigs$qseqid) {

SampleID <- gvp_contigs %>%
                  filter(seq == qseqid) %>%
                  select(SampleID) 

query_name <- gvp_contigs %>%
                  filter(seq == qseqid) %>%
                  select(query_name) 

#symlink was giving issues (likely GLAMR permissions)
input_fasta <- paste0("../data/extract_refine_seqs_gvp/assembly/megahit_noNORM/", SampleID, "_final.contigs.renamed.fa")

output_fasta <- paste0("../data/extract_refine_seqs_gvp/contigs/kraken/gvp_contigs/", query_name, "_gvpAC_contig_extract.fa")

# Read the FASTA file using Biostrings
fasta_data <- Biostrings::readDNAStringSet(input_fasta, format = "fasta")

# Convert to tibble for easier manipulation
fasta_df <- tibble(
  name = names(fasta_data),
  sequence = as.character(fasta_data))

# Extract the contig of interest from the tibble
contig_sequence <- fasta_df %>%
  filter(name == seq) %>%
  pull(sequence) %>%
  DNAStringSet() # Convert to a DNAString object

# Add query name to contig sequence
names(contig_sequence) <- query_name  # Set the name of the DNAString object

# Write the contig to the new FASTA file
writeXStringSet(contig_sequence, output_fasta)

} 

```

4.) Run Kraken to annotate contigs with taxonomic classification
```{bash}

#Runs Kraken2 to annotate contigs
snakemake run_kraken2_gvpAC_contigs_pluspf --profile config/profiles/vondamm/

```

5.) Analyze Kraken output to determine Microcystis contigs
```{r}

#Gather all Kraken output files
kraken_paths <- system("ls ../data/extract_refine_seqs_gvp/output/kraken/gvp_contigs/gvpAC_contigs_pluspf/*_output.txt", intern = TRUE) %>% 
  tibble(output_path = .) 

# Read and combine all .txt files into a single data frame
# Initialize an empty data frame to store results
combined_kraken_output <- tibble() 

# Loop through each file path and append data
for (path in kraken_paths$output_path) {
  # Read the file with generic column names
  file_data <- read_delim(path, delim = "\t", col_names = FALSE, show_col_types = FALSE) %>%
    mutate(source_file = basename(path)) 

  # Append to combined_data
  combined_kraken_output <- bind_rows(combined_kraken_output, file_data) 
}

#Rename columns:
combined_kraken_output_rename <- combined_kraken_output %>%
                                      dplyr::rename("contig" = "X2",
                                             "kraken_tax" = "X3") 

#Keep only contigs identified as Microcystis
combined_kraken_output_mcy <- combined_kraken_output_rename %>%
                                            filter(str_detect(kraken_tax, "Microcystis"))   # Filter rows containing "Microcystis" annotations in column 3

```

6a.) Run Bakta to create .gbf (newer version of .gbk) files for clinker visulaization
```{r}

#Gather all Kraken input files
kraken_input_contigs <- system("ls ../data/extract_refine_seqs_gvp/contigs/kraken/gvp_contigs/*.fa", intern = TRUE) %>% 
  tibble(fasta_path = .) %>%
  mutate(contig_name = fasta_path %>% str_remove(".*gvp_contigs/") %>% str_remove("_gvpAC_contig_extract.fa"))

#Make list of the contigs of interest (annotated as Microcystis) - filter out list above^
mcy_contigs_oi <- kraken_input_contigs %>%
      filter(contig_name %in% combined_kraken_output_mcy$contig) #generated in Kraken analysis chunk



######CODE EDIT ENDED - - -  no relative paths yet
#symlink these contigs to process using Bakta
mcy_contigs_oi <- mcy_contigs_oi %>%
                      mutate(bakta_input = paste0("/geomicro/data2/pdenuyl2/metagenomics_wg24/output/clinker/gvp_contigs/bakta/input/", contig_name, "_gvpAC_contig_extract.fa")) 

#symbolic link contig_paths
#file.symlink(mcy_contigs_oi$fasta_path, mcy_contigs_oi$bakta_input)

```

6b.) Run Bakta to format Microcystis contigs to .gbff (GenBank format, newer version of .gbk)
```{bash}

snakemake run_bakta_mcy_buoyancy_contigs --profile config/profiles/vondamm/ -dry-run

```

7.) Run Clinker to visualize Microcystis contigs with both gvpA and gvpC genes
```{bash}

snakemake run_bakta_mcy_buoyancy_contigs --profile config/profiles/vondamm/ -dry-run

```

8.) 
Extract genes using bedtools
We want to setup files to blast every gene on contig: samp_4400_818442_Lake_Huron_gvpAC_contig_extract.fa
```{bash}
#Set working directory for bakta outputs - contig of interest
cd ../output/clinker/gvp_contigs/bakta/output/samp_4400_818442_Lake_Huron_gvpAC_contig_extract/

#Extract genes from fasta (.fna) sequence. Curate for blast database.
bedtools getfasta \
-fi samp_4400_818442_Lake_Huron_gvpAC_contig_extract.fna \
-bed samp_4400_818442_Lake_Huron_gvpAC_contig_extract.gff3 \
-fo samp_4400_818442_Lake_Huron_gvpAC_contig_extract_genes_bed.fa

#Manually curate blast database from new output (samp_4400_818442_Lake_Huron_gvpAC_contig_extract_bed.fa)
# Remove the first sequence as it's just the entire contig
# Annotate individual genes for next blastn step
# now file: samp_4400_818442_Lake_Huron_gvpAC_contig_extract_genes_bed_curated.fa
cp samp_4400_818442_Lake_Huron_gvpAC_contig_extract_genes_bed_curated.fa /geomicro/data2/pdenuyl2/CIGLR_bioinformatics/2025/SagBay/blast/database/nucl/blastdbbuoyancysamp4400818442LH.fasta
```

blastn set_41 assemblies vs genes on contig: samp_4400_818442_Lake_Huron_gvpAC_contig_extract.fa
```{bash}

snakemake run_blastn_assemblies_samp_4400_818442_Lake_Huron_gvpAC --profile config/profiles/vondamm/

```

Process blastn output (from microcystis contigs) to extract hits for each gene of interest on samp_4400_818442_Lake_Huron_gvpAC_contig_extract contig - identify top hits and coordinates on contig
```{r}

#Make list of blastn result outputs
blastn_assemblies_list <- system("ls /geomicro/data2/pdenuyl2/CIGLR_bioinformatics/2025/SagBay/blast/output/buoyancy/blastn/assemblies/*blastdbbuoyancysamp4400818442LH_contigs_blastn.tsv", intern=TRUE) 

#Include only files with results in list
blastn_assemblies_list_results <- blastn_assemblies_list[file.size(blastn_assemblies_list) > 0]

#Bind rows of all contig blastn results
blastn_assemblies_results_vroom <- vroom(blastn_assemblies_list_results, col_names = FALSE, show_col_types = FALSE, delim = "\t")

#Add column names - corresponding to blast output flag -outfmt '6 std qcovs stitle'
colnames(blastn_assemblies_results_vroom) <- c("qseqid", "sseqid", "pident", "length", "mismatch", "gapopen", "qstart", "qend", "sstart", "send", "evalue", "bitscore", "qcovs", "stitle", "qlen") #added qlen Sept 26, 2024 for Buoyancy analysis

#Column name reference: https://www.metagenomics.wiki/tools/blast/blastn-output-format-6
#1.  qseqid      query or source (e.g., gene) sequence id
#2.  sseqid      subject  or target (e.g., reference genome) sequence id
#3.  pident      percentage of identical matches
#4.  length      alignment length (sequence overlap)
#5.  mismatch    number of mismatches
#6.  gapopen     number of gap openings
#7.  qstart      start of alignment in query
#8.  qend        end of alignment in query
#9.  sstart      start of alignment in subject
#10. send        end of alignment in subject
#11. evalue      expect value
#12. bitscore    bit score
#13. qcovs       query coverage per subject
#14. stitle      subject title
#15. qlen        query length

#Make column for general toxin target id, toxin gene target, and sample ids
blastn_assemblies_results_vroom_add <- blastn_assemblies_results_vroom %>% mutate(target = substr(sseqid, 1, 3),
                                                                                  gene_target = substr(sseqid, 1,4),
                                                                                  SampleID = qseqid %>% str_extract("samp_.*_") %>% str_sub(end = -2))

# Sort by query positions and remove overlapping hits
blastn_buoyancy_assemblies_id_overlap <- blastn_assemblies_results_vroom_add %>%
  arrange(qseqid, qstart) %>%       # Sort by query start position
  group_by(qseqid, gene_target) %>%
  mutate(overlap_group = cumsum(c(1, diff(qend) > 0)))  # Creates overlap groups

#For each group, take the lowest e-value hit (best hit for each unique hit)
blastn_buoyancy_assemblies_best_hits <- blastn_buoyancy_assemblies_id_overlap %>%
  group_by(qseqid, gene_target, overlap_group) %>%
  filter(evalue == min(evalue)) %>%  # Keep only the hit with the lowest evalue
  ungroup()

######IMPORTANT!!!#######
#Since we're blasting the original assemblies, our kraken annotations for microcystis have not yet been considered
#########################
#Implement now
#Filter out only contigs that were identified as Microcystis by kraken
blastn_buoyancy_assemblies_best_hits_mcy <- blastn_buoyancy_assemblies_best_hits %>%
                                                      filter(qseqid %in% combined_kraken_output_mcy_rename$contig)

#Merge metadata, so there's a geo_loc_name for each sample
GLAMR_sample_table_set41_read_select <- GLAMR_sample_table_set41_read %>%
                                                                  select("SampleID", "geo_loc_name")

blastn_buoyancy_assemblies_geo_loc_name <- left_join(blastn_buoyancy_assemblies_best_hits_mcy, GLAMR_sample_table_set41_read_select, by = "SampleID") %>%
                                                                  mutate(query_name = paste0(qseqid, "_", geo_loc_name) %>%
                                                                           gsub(" ", "_", .))

#Make table of gvp gene lengths
#First import gvp gene database
blastdbbuoyancysamp4400818442LH <- readDNAStringSet(filepath = "/geomicro/data2/pdenuyl2/CIGLR_bioinformatics/2025/SagBay/blast/database/nucl/blastdbbuoyancysamp4400818442LH.fasta") 

#Make a table with corresponding 90% length cutoff for each sequence
names_width_table <- data.frame(
  subject = names(blastdbbuoyancysamp4400818442LH),
  ref_width = width(blastdbbuoyancysamp4400818442LH)
) %>%
  mutate(cutoff_width = (ref_width * .9) %>% round(.))

####IMPORTANT QC STEP!!!!!######
#Filter blast hits for 90% reference gene length cutoff
blastn_buoyancy_assemblies_length_cutoff <- blastn_buoyancy_assemblies_geo_loc_name %>%
  inner_join(names_width_table, by = c("sseqid" = "subject")) %>%
  filter(length >= cutoff_width) %>%
  mutate(qseqid_gene_start_stop = paste0(qseqid, "_", gene_target, "_", qstart, "_", qend))

#Prep for next chunk
#Make a quick distinction between gvpA_contig_1:41-257 and gvpA_contig_1:2849-3260
blastn_buoyancy_assemblies_length_cutoff <- blastn_buoyancy_assemblies_length_cutoff %>%
  mutate(
    gene_target_specific = case_when(
      sseqid == "gvpA_contig_1:41-257" ~ "gvpA1",
      sseqid == "gvpA_contig_1:2849-3260" ~ "gvpA2",
      sseqid == "gvpL_gvpF_family_contig_1:5891-6575" ~ "gvpLF",
      TRUE ~ gene_target
    )
  )

```

Extract genes for tree building
```{r}

gvp_genes <- blastn_buoyancy_assemblies_length_cutoff
####################################
#Extract contigs by gene_target_specific 
####################################
for (seq in gvp_genes_tree$qseqid_gene_start_stop) {

SampleID <- gvp_genes %>%
                  filter(seq == qseqid_gene_start_stop) %>%
                  select(SampleID) 

query_name <- gvp_genes %>%
                  filter(seq == qseqid_gene_start_stop) %>%
                  select(qseqid) 

geo_loc <- gvp_genes %>%
                  filter(seq == qseqid_gene_start_stop) %>%
            mutate(
                gene_loc_name_case = case_when(
                geo_loc_name == "Lake Erie" ~ "Lake_Erie",
                geo_loc_name == "Lake Huron" ~ "Lake_Huron",)) %>%
                select(gene_loc_name_case)

gene_target <- gvp_genes %>%
                  filter(seq == qseqid_gene_start_stop) %>%
                  select(gene_target) 

qstart <- as.numeric(gvp_genes %>%
                  filter(seq == qseqid_gene_start_stop) %>%
                  select(qstart))

qend <- as.numeric(gvp_genes %>%
                  filter(seq == qseqid_gene_start_stop) %>%
                  select(qend))

gene_target_specific <- gvp_genes %>%
                  filter(seq == qseqid_gene_start_stop) %>%
                  select(gene_target_specific) 

input_fasta <- paste0("blast/query/assemblies_vs_buoyancy/", SampleID, "_final.contigs.renamed.fa")
  
output_fasta <- paste0("tree_building/", gene_target, "/extract_seqs/", query_name, "_", geo_loc, "_", gene_target_specific, "_", qstart, "_", qend, "_extract.fa")

# Read the FASTA file using Biostrings
fasta_data <- readDNAStringSet(input_fasta, format = "fasta")

# Convert to tibble for easier manipulation
fasta_df <- tibble(
  name = names(fasta_data),
  sequence = as.character(fasta_data))

# Extract the contig of interest from the tibble
contig_sequence <- fasta_df %>%
  filter(name %in% query_name) %>%
  pull(sequence) %>%
  DNAStringSet() # Convert to a DNAString object

# Extract the region from qstart to qend
extracted_gene <- subseq(contig_sequence, start = qstart, end = qend)

# Add query name to contig sequence
names(extracted_gene) <- paste0(query_name, "_", geo_loc, "_", gene_target_specific, "_", qstart, "_", qend, "_extract")  # Set the name of the DNAString object

# Write the contig to the new FASTA file
writeXStringSet(extracted_gene, output_fasta)

} 

```


